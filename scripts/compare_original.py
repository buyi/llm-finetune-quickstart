#!/usr/bin/env python3
"""
å¯¹æ¯”åŸå§‹æ¨¡å‹ - éªŒè¯å¾®è°ƒæ•ˆæœ
"""

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

def test_original_model():
    """æµ‹è¯•åŸå§‹Qwen2-0.5Bæ¨¡å‹"""
    print("ğŸ“¥ åŠ è½½åŸå§‹ Qwen2-0.5B æ¨¡å‹...")
    
    # åŠ è½½åŸå§‹æ¨¡å‹
    model = AutoModelForCausalLM.from_pretrained(
        'Qwen/Qwen2-0.5B',
        torch_dtype=torch.float32,
        device_map=None,
        trust_remote_code=True
    )
    tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2-0.5B', trust_remote_code=True)
    
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    print("âœ… åŸå§‹æ¨¡å‹åŠ è½½å®Œæˆ")
    
    # æµ‹è¯•é—®é¢˜
    test_prompts = [
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "ç”¨Pythonå†™ä¸€ä¸ªè®¡ç®—é˜¶ä¹˜çš„å‡½æ•°",
        "å°†è¿™å¥è¯ç¿»è¯‘æˆè‹±æ–‡ï¼šä»Šå¤©å¤©æ°”å¾ˆå¥½"
    ]
    
    print("\n" + "="*60)
    print("ğŸ§ª åŸå§‹æ¨¡å‹æµ‹è¯•")
    print("="*60)
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\nğŸ“ æµ‹è¯• {i}: {prompt}")
        print("-" * 40)
        
        # æ ¼å¼åŒ–æç¤º
        formatted_prompt = f"### æŒ‡ä»¤ï¼š\n{prompt}\n\n### å›ç­”ï¼š\n"
        inputs = tokenizer(formatted_prompt, return_tensors="pt", truncation=True)
        
        # ç”Ÿæˆå›ç­”
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=100,
                temperature=0.7,
                do_sample=True,
                top_p=0.9,
                pad_token_id=tokenizer.pad_token_id,
                eos_token_id=tokenizer.eos_token_id
            )
        
        # è§£ç 
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        response = response[len(formatted_prompt):].strip()
        
        print(f"ğŸ¤– åŸå§‹æ¨¡å‹: {response[:200]}...")
    
    print(f"\nğŸ’¡ å¯¹æ¯”æ–¹æ³•:")
    print(f"   ç°åœ¨è¿è¡Œä½ çš„å¾®è°ƒæ¨¡å‹:")
    print(f"   python scripts/simple_inference.py")
    print(f"   ç”¨ç›¸åŒé—®é¢˜æµ‹è¯•ï¼Œå¯¹æ¯”å›ç­”è´¨é‡ï¼")

if __name__ == "__main__":
    test_original_model()